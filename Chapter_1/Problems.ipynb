{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Basic Binary Classification Neuron\n",
    "**Task**: Construct a single neuron to determine if a number is positive or negative.\n",
    "- **Inputs**: Single feature, a real number \\( x \\).\n",
    "- **Weights and Bias**: Initialize weight \\( w = 1.0 \\) and bias \\( b = 0 \\).\n",
    "- **Activation Function**: Use the sigmoid function to output a probability.\n",
    "- **Task**: Write the mathematical model of this neuron and manually calculate the output for \\( x = 2 \\) and \\( x = -1 \\).\n",
    "\n",
    "### Problem 2: Understanding Activation Functions\n",
    "**Task**: Compare the outputs of a neuron with three different activation functions given a fixed input.\n",
    "- **Inputs**: Assume a constant input \\( x = -0.5 \\) with weight \\( w = 1.0 \\) and bias \\( b = 0.5 \\).\n",
    "- **Activation Functions**: Use sigmoid, tanh, and ReLU.\n",
    "- **Task**: Calculate the output for each activation function and describe the effect of each function on the neuron's output.\n",
    "\n",
    "### Problem 3: Output Behavior for Different Inputs\n",
    "**Task**: Model a neuron that predicts whether an object's size is above or below a threshold.\n",
    "- **Inputs**: Single feature representing size (e.g., \\( x = 10 \\)).\n",
    "- **Weights and Bias**: Assume \\( w = 0.1 \\) and \\( b = -1 \\).\n",
    "- **Activation Function**: Use the sigmoid function to model the output.\n",
    "- **Task**: Describe how the output of the neuron changes as the size value varies from 5 to 15.\n",
    "\n",
    "### Problem 4: Impact of Bias in Activation\n",
    "**Task**: Explore the impact of varying the bias on a neuron's output with a fixed input.\n",
    "- **Inputs**: Assume \\( x = 2.0 \\).\n",
    "- **Weights and Bias**: Use \\( w = 1.5 \\) and experiment with different bias values \\( b = -1, 0, 1 \\).\n",
    "- **Activation Function**: Use the ReLU function.\n",
    "- **Task**: Calculate and compare the outputs for each bias setting, discussing the role of bias in modulating the neuron's activation.\n",
    "\n",
    "These problems help you understand how single neurons function, focusing on the basics of input processing, weight and bias effects, and how activation functions shape the neuron's output. They provide a practical introduction to neural network fundamentals without delving into more complex network architectures."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
